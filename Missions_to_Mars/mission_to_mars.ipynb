{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BeautifulSoup\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Splinter and set the chromedriver path\n",
    "from splinter import Browser\n",
    "executable_path = {\"executable_path\": \"/usr/local/bin/chromedriver\"}\n",
    "browser = Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping news from NASA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the following URL\n",
    "url = \"https://mars.nasa.gov/news/\"\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the page into Soup\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fastest way to get the top article and headline\n",
    "current_news_title = browser.find_by_css(\".content_title\")[0].text\n",
    "current_news_p = browser.find_by_css(\".article_teaser_body\")[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASA's Curiosity Rover Finds an Ancient Oasis on Mars\n",
      "New evidence suggests salty, shallow ponds once dotted a Martian crater — a sign of the planet's drying climate.\n"
     ]
    }
   ],
   "source": [
    "print(current_news_title)\n",
    "print(current_news_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I misunderstood and thought we needed to scrape all articles and headlines on the page\n",
    "# Below is the procedure for how I gathered them and put them into a list of dictionaries\n",
    "\n",
    "# Using list comprehension to get all titles and articles\n",
    "# Headline: class = \"content_title\"\n",
    "news_title = [link.text for link in browser.find_by_css(\".content_title\")]\n",
    "\n",
    "# This appears to be the class for short paragraphs: <div class='rollover_description_inner'>\n",
    "news_p = [link.text for link in browser.find_by_css(\".article_teaser_body\")]\n",
    "\n",
    "# List to hold dictionary\n",
    "mars_news = []\n",
    "\n",
    "# Making a list of dictionaries \n",
    "\n",
    "# It turns out there are a bunch of empty entries at the end of the news_title list;\n",
    "# happily, the entries before the end correspond with the news paragraphs of the same index\n",
    "\n",
    "# Rather than clean up the news_title list, I can just set the while loop to end when the \n",
    "# news_p list ends and it amounts to the same thing.\n",
    "\n",
    "i = 0\n",
    "\n",
    "while i < len(news_p):\n",
    "    mars_news.append(\n",
    "    {'news_title': news_title[i], 'news_p': news_p[i]}\n",
    "    )\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'news_title': \"NASA's Curiosity Rover Finds an Ancient Oasis on Mars\",\n",
       "  'news_p': \"New evidence suggests salty, shallow ponds once dotted a Martian crater — a sign of the planet's drying climate.\"},\n",
       " {'news_title': \"NASA's Mars 2020 Rover Tests Descent-Stage Separation\",\n",
       "  'news_p': \"A crane lifts the rocket-powered descent stage away from NASA's Mars 2020 rover after technicians tested the pyrotechnic charges that separate the two spacecraft.\"},\n",
       " {'news_title': \"NASA's Push to Save the Mars InSight Lander's Heat Probe\",\n",
       "  'news_p': \"The scoop on the end of the spacecraft's robotic arm will be used to 'pin' the mole against the wall of its hole.\"}]"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mars_news[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedure if I wanted to zip the lists together and convert them to a single dictionary \n",
    "# where the title is the key and the article is the value\n",
    "\n",
    "# # Zipping together the lists\n",
    "# NASA_zip = zip(news_title, news_p)\n",
    "\n",
    "# # Converting to a dictionary \n",
    "# NASA_dict = dict((x,y) for x, y in NASA_zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting featured image from NASA JPL Mars Space Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New URL -- JPL Mars Space Images\n",
    "url = \"https://jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beautiful soup needs to be updated for the new URL\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image source\n",
    "img_source = soup.find(class_ = \"carousel_item\")['style']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "background-image: url('/spaceimages/images/wallpaper/PIA16227-1920x1200.jpg');\n"
     ]
    }
   ],
   "source": [
    "# print(img_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I only need what's between the quotation marks, so I'll split the string on those\n",
    "# get the second element\n",
    "img_string = img_source.split(\"'\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/spaceimages/images/wallpaper/PIA16227-1920x1200.jpg\n"
     ]
    }
   ],
   "source": [
    "# print(img_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need the base url, then I can add the path\n",
    "base_url = \"https://jpl.nasa.gov\"\n",
    "\n",
    "# the image URL\n",
    "featured_image_url = base_url + img_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://jpl.nasa.gov/spaceimages/images/wallpaper/PIA16227-1920x1200.jpg\n"
     ]
    }
   ],
   "source": [
    "print(featured_image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting latest tweet from Mars Weather twitter account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change browser to twitter\n",
    "url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class is \"TweetTextSize\"\n",
    "# using Splinter within a list comprehension to strip the tweet down to its text; we want the top \n",
    "# tweet, so that's index 0\n",
    "mars_weather = [tweet.text.strip() for tweet in browser.find_by_css(\".TweetTextSize\")][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InSight sol 309 (2019-10-10) low -102.3ºC (-152.1ºF) high -26.2ºC (-15.1ºF)\n",
      "winds from the SSE at 6.1 m/s (13.6 mph) gusting to 18.9 m/s (42.4 mph)\n",
      "pressure at 7.20 hPa\n"
     ]
    }
   ],
   "source": [
    "# Looks good!\n",
    "print(mars_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping a table about Mars from Space Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change browser to Space Facts\n",
    "url = \"https://space-facts.com/mars/\"\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Beautiful Soup to scrape table\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "table = soup.find_all('table')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to render to table string\n",
    "mars_facts = pd.read_html(str(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  Mars - Earth Comparison             Mars            Earth\n",
      "0               Diameter:         6,779 km        12,742 km\n",
      "1                   Mass:  6.39 × 10^23 kg  5.97 × 10^24 kg\n",
      "2                  Moons:                2                1\n",
      "3      Distance from Sun:   227,943,824 km   149,598,262 km\n",
      "4         Length of Year:   687 Earth days      365.24 days\n",
      "5            Temperature:    -153 to 20 °C      -88 to 58°C]\n"
     ]
    }
   ],
   "source": [
    "# Table string looks good\n",
    "print(mars_facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"Mars - Earth Comparison\":\"Diameter:\",\"Mars\":\"6,779 km\",\"Earth\":\"12,742 km\"},{\"Mars - Earth Comparison\":\"Mass:\",\"Mars\":\"6.39 \\u00d7 10^23 kg\",\"Earth\":\"5.97 \\u00d7 10^24 kg\"},{\"Mars - Earth Comparison\":\"Moons:\",\"Mars\":\"2\",\"Earth\":\"1\"},{\"Mars - Earth Comparison\":\"Distance from Sun:\",\"Mars\":\"227,943,824 km\",\"Earth\":\"149,598,262 km\"},{\"Mars - Earth Comparison\":\"Length of Year:\",\"Mars\":\"687 Earth days\",\"Earth\":\"365.24 days\"},{\"Mars - Earth Comparison\":\"Temperature:\",\"Mars\":\"-153 to 20 \\u00b0C\",\"Earth\":\"-88 to 58\\u00b0C\"}]\n"
     ]
    }
   ],
   "source": [
    "# Converting table to JSON\n",
    "mars_table = mars_facts[0].to_json(orient='records')\n",
    "print(mars_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mars - Earth Comparison</th>\n",
       "      <th>Mars</th>\n",
       "      <th>Earth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Diameter:</td>\n",
       "      <td>6,779 km</td>\n",
       "      <td>12,742 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mass:</td>\n",
       "      <td>6.39 × 10^23 kg</td>\n",
       "      <td>5.97 × 10^24 kg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Moons:</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Distance from Sun:</td>\n",
       "      <td>227,943,824 km</td>\n",
       "      <td>149,598,262 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Length of Year:</td>\n",
       "      <td>687 Earth days</td>\n",
       "      <td>365.24 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Temperature:</td>\n",
       "      <td>-153 to 20 °C</td>\n",
       "      <td>-88 to 58°C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Mars - Earth Comparison             Mars            Earth\n",
       "0               Diameter:         6,779 km        12,742 km\n",
       "1                   Mass:  6.39 × 10^23 kg  5.97 × 10^24 kg\n",
       "2                  Moons:                2                1\n",
       "3      Distance from Sun:   227,943,824 km   149,598,262 km\n",
       "4         Length of Year:   687 Earth days      365.24 days\n",
       "5            Temperature:    -153 to 20 °C      -88 to 58°C"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a dataframe that's unnecessary for the .py file but looks cool\n",
    "df = pd.read_json(mars_table)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------+-----------------+-----------------+\n",
      "|    | Mars - Earth Comparison   | Mars            | Earth           |\n",
      "|----+---------------------------+-----------------+-----------------|\n",
      "|  0 | Diameter:                 | 6,779 km        | 12,742 km       |\n",
      "|  1 | Mass:                     | 6.39 × 10^23 kg | 5.97 × 10^24 kg |\n",
      "|  2 | Moons:                    | 2               | 1               |\n",
      "|  3 | Distance from Sun:        | 227,943,824 km  | 149,598,262 km  |\n",
      "|  4 | Length of Year:           | 687 Earth days  | 365.24 days     |\n",
      "|  5 | Temperature:              | -153 to 20 °C   | -88 to 58°C     |\n",
      "+----+---------------------------+-----------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "# Just for giggles, here's a printout in ASCII\n",
    "from tabulate import tabulate\n",
    "print( tabulate(mars_facts[0], headers='keys', tablefmt='psql') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting high-res pictures of the Mars hemispheres from USGS.gov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\n"
     ]
    }
   ],
   "source": [
    "# Changing url to usgs.gov\n",
    "url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "browser.visit(url)\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating Beautiful Soup\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.usgs.gov/centers/astrogeo-sc\n",
      "https://nasa.gov\n",
      "https://pds-imaging.jpl.nasa.gov/\n",
      "/search\n",
      "/search/map/Mars/Viking/cerberus_enhanced\n",
      "/search/map/Mars/Viking/cerberus_enhanced\n",
      "/search/map/Mars/Viking/schiaparelli_enhanced\n",
      "/search/map/Mars/Viking/schiaparelli_enhanced\n",
      "/search/map/Mars/Viking/syrtis_major_enhanced\n",
      "/search/map/Mars/Viking/syrtis_major_enhanced\n",
      "/search/map/Mars/Viking/valles_marineris_enhanced\n",
      "/search/map/Mars/Viking/valles_marineris_enhanced\n",
      "http://isis.astrogeology.usgs.gov\n",
      "http://planetarynames.wr.usgs.gov\n",
      "https://astrogeology.usgs.gov/tools/map-a-planet-2\n",
      "https://www.usgs.gov/centers/astrogeo-sc/science/cartography-and-imaging-sciences-node-nasa-planetary-data-system\n",
      "https://www.usgs.gov/centers/astrogeo-sc/science/regional-planetary-image-facility-rpif\n",
      "https://www.usgs.gov/centers/astrogeo-sc/science/usgsnasa-planetary-photogrammetry-guest-facility\n",
      "http://pilot.wr.usgs.gov\n",
      "https://www.usgs.gov/centers/astrogeo-sc/science/mrctr-gis-lab\n",
      "http://astrogeology.usgs.gov/search\n",
      "http://astrogeology.usgs.gov/maps/about\n",
      "http://astrogeology.usgs.gov/maps/contact\n",
      "https://www.usgs.gov/centers/astrogeo-sc\n"
     ]
    }
   ],
   "source": [
    "# splinter can click links to navigate to new pages -- but only if they're in full URL form\n",
    "# NOTE: the ones we need, i.e., the Mars hemisphere links, are not clickable!\n",
    "\n",
    "for link in soup.find_all('a'):\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will hit the live link to NASA above, and splinter will click it and take the browser there\n",
    "browser.click_link_by_partial_href('nasa.gov')\n",
    "\n",
    "# Unfortunately, splinter will not take the browser to the image links, even when I've added them\n",
    "# to a full URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll need to do a number of things to get image names and links:\n",
    "\n",
    "# 1) Set up a loop to find all the hemisphere names, pulling by h3 tag, \n",
    "#    then cleaning up the names and saving them to a list\n",
    "# 2) Set up another loop to find all the paths to the pages that have a link to the larger image\n",
    "# 3) Set up a third loop to take browser to the new pages and grab the image link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "\n",
    "# I'll make a list to contain the elements; 'title' is what the project calls for\n",
    "title = []\n",
    "\n",
    "# There are four elements to find, so I'll set this up to loop four times\n",
    "i = 0\n",
    "\n",
    "while i < 4:\n",
    "    hemisphere = soup.find_all('h3')[i].text.strip()\n",
    "    # This strips \"Enhanced\" off the end of the string\n",
    "    hemisphere = hemisphere[:-9]\n",
    "    # Append to my list\n",
    "    title.append(hemisphere)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cerberus Hemisphere',\n",
       " 'Schiaparelli Hemisphere',\n",
       " 'Syrtis Major Hemisphere',\n",
       " 'Valles Marineris Hemisphere']"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2\n",
    "\n",
    "# Now I'll need a list to contain the URL paths\n",
    "paths = []\n",
    "\n",
    "# It turns out that there are duplicates for each path, so the loop needs to run 8 times instead of 4\n",
    "# and I'll increment by two so that I only capture one instance of the path\n",
    "\n",
    "i = 0\n",
    "\n",
    "while i < 8:\n",
    "    path = soup.find_all('a', class_ = 'itemLink product-item')[i]['href']\n",
    "    paths.append(path)\n",
    "    i+=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/search/map/Mars/Viking/cerberus_enhanced',\n",
       " '/search/map/Mars/Viking/schiaparelli_enhanced',\n",
       " '/search/map/Mars/Viking/syrtis_major_enhanced',\n",
       " '/search/map/Mars/Viking/valles_marineris_enhanced']"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3-A\n",
    "\n",
    "# I need the base URL so that I can add the path for each new browser visit\n",
    "base_url = \"https://astrogeology.usgs.gov\"\n",
    "\n",
    "# I'll make a list to contain full URLs\n",
    "url_list = []\n",
    "\n",
    "# I'll make the full URLs by attaching the contents of my paths list to the end of the base_url\n",
    "for path in paths:\n",
    "    url = base_url + path\n",
    "    url_list.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://astrogeology.usgs.gov/search/map/Mars/Viking/cerberus_enhanced',\n",
       " 'https://astrogeology.usgs.gov/search/map/Mars/Viking/schiaparelli_enhanced',\n",
       " 'https://astrogeology.usgs.gov/search/map/Mars/Viking/syrtis_major_enhanced',\n",
       " 'https://astrogeology.usgs.gov/search/map/Mars/Viking/valles_marineris_enhanced']"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3-B\n",
    "\n",
    "# I'll make a list to hold the image url I'm going to scrape\n",
    "image_url = []\n",
    "\n",
    "# I'll cycle through the URLs in my url_list, taking the browser to each and getting the image URL out\n",
    "\n",
    "for url in url_list:\n",
    "    \n",
    "    browser.visit(url)\n",
    "    \n",
    "    # Beautiful soup needs to be updated for the new URL\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    # Pull out the image link \n",
    "    img_source = soup.find('img', class_ = \"wide-image\")['src']\n",
    "    \n",
    "    # The image source URL is just a path, so I'll need to make a full url to add to the list\n",
    "    img_url = base_url + img_source\n",
    "    \n",
    "    # Add to list\n",
    "    image_url.append(img_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://astrogeology.usgs.gov/cache/images/cfa62af2557222a02478f1fcd781d445_cerberus_enhanced.tif_full.jpg',\n",
       " 'https://astrogeology.usgs.gov/cache/images/3cdd1cbf5e0813bba925c9030d13b62e_schiaparelli_enhanced.tif_full.jpg',\n",
       " 'https://astrogeology.usgs.gov/cache/images/ae209b4e408bb6c3e67b6af38168cf28_syrtis_major_enhanced.tif_full.jpg',\n",
       " 'https://astrogeology.usgs.gov/cache/images/7cf2da4bf549ed01c17f206327be4db7_valles_marineris_enhanced.tif_full.jpg']"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I need to make dictionaries for each image, with title and image_url as keys\n",
    "\n",
    "# I'll store them in this list:\n",
    "hemisphere_image_urls = []\n",
    "\n",
    "# Now use a while loop to capture them as separate dictionaries (as opposed to zipping into tuples)\n",
    "# The while will allow me to use an index\n",
    "i = 0\n",
    "\n",
    "while i < 4:\n",
    "    hemisphere_image_urls.append(\n",
    "    {'title': title[i], 'image_url': image_url[i]})\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Cerberus Hemisphere',\n",
       "  'image_url': 'https://astrogeology.usgs.gov/cache/images/cfa62af2557222a02478f1fcd781d445_cerberus_enhanced.tif_full.jpg'},\n",
       " {'title': 'Schiaparelli Hemisphere',\n",
       "  'image_url': 'https://astrogeology.usgs.gov/cache/images/3cdd1cbf5e0813bba925c9030d13b62e_schiaparelli_enhanced.tif_full.jpg'},\n",
       " {'title': 'Syrtis Major Hemisphere',\n",
       "  'image_url': 'https://astrogeology.usgs.gov/cache/images/ae209b4e408bb6c3e67b6af38168cf28_syrtis_major_enhanced.tif_full.jpg'},\n",
       " {'title': 'Valles Marineris Hemisphere',\n",
       "  'image_url': 'https://astrogeology.usgs.gov/cache/images/7cf2da4bf549ed01c17f206327be4db7_valles_marineris_enhanced.tif_full.jpg'}]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hemisphere_image_urls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
